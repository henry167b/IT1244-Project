{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we attempt to use a python library called textblob which is mainly used for the transformation of text data. As we have identified, tweets commonly have many spelling and grammar mistakes that needs to be rectified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/henry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/henry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "   labels                                               text\n",
      "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1       0  is upset that he can't update his Facebook by ...\n",
      "2       0  @Kenichan I dived many times for the ball. Man...\n",
      "3       0    my whole body feels itchy and like its on fire \n",
      "4       0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../Twitter Sentiment/dataset.csv', header=None)\n",
    "data.columns = ['labels', 'text']\n",
    "print(len(data))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package \"TextBlob\" was one of the package we experimented with. It actually has its own sentiment analysis method. The output of the polarity ranges from -1 to 1 and the huge number of 0s (neutral) indicate that there is actually a lot of data that the model is unable to classify and hence we decided to not go ahead with it in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in range(24999, 75000):\n",
    "    string = data.text[i]\n",
    "    tb = TextBlob(string)\n",
    "    prob = tb.sentiment.polarity\n",
    "    predictions.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17789"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x==0, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data once again \n",
    "data = data = pd.read_csv('../Twitter Sentiment/dataset.csv', header=None)\n",
    "data.columns = ['labels', 'text']\n",
    "print(len(data))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^A-Za-z\\']+', ' ', text)  # Keep only letters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using autocorrect library as it runs the fastest and most autocorrect libraries would perform equally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "check = Speller(lang = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = []\n",
    "\n",
    "for sentence in data.cleaned_text:\n",
    "    sample_txt.append(check(sentence))\n",
    "\n",
    "data['spelled'] = sample_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the data first as the above step took very long to execute everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('spelt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>spelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww that's a bummer you shoulda got david ca...</td>\n",
       "      <td>www that's a summer you should got david carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dived many times for the ball managed to sa...</td>\n",
       "      <td>i dived many times for the ball managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itch and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no it's not behaving at all i'm mad why am i ...</td>\n",
       "      <td>no it's not behaving at all i'm mad why am i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "      <td>Now need 8 followers to compleate 1000  Follow...</td>\n",
       "      <td>now need followers to compleate follow</td>\n",
       "      <td>now need followers to complete follow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1</td>\n",
       "      <td>I knew I had to explain something to my friend...</td>\n",
       "      <td>i knew i had to explain something to my friend...</td>\n",
       "      <td>i knew i had to explain something to my friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>done tweeting..... til tomorrow..</td>\n",
       "      <td>done tweeting til tomorrow</td>\n",
       "      <td>done meeting til tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>@cmozilo Act II set is pretty breath-taking -L...</td>\n",
       "      <td>act ii set is pretty breath taking love the r...</td>\n",
       "      <td>act ii set is pretty breath taking love the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>if you don't have an artfire account to sell y...</td>\n",
       "      <td>if you don't have an artfire account to sell y...</td>\n",
       "      <td>if you don't have an attire account to sell yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                               text  \\\n",
       "0           0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1           0  is upset that he can't update his Facebook by ...   \n",
       "2           0  @Kenichan I dived many times for the ball. Man...   \n",
       "3           0    my whole body feels itchy and like its on fire    \n",
       "4           0  @nationwideclass no, it's not behaving at all....   \n",
       "...       ...                                                ...   \n",
       "99995       1  Now need 8 followers to compleate 1000  Follow...   \n",
       "99996       1  I knew I had to explain something to my friend...   \n",
       "99997       1                 done tweeting..... til tomorrow..    \n",
       "99998       1  @cmozilo Act II set is pretty breath-taking -L...   \n",
       "99999       1  if you don't have an artfire account to sell y...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0       awww that's a bummer you shoulda got david ca...   \n",
       "1      is upset that he can't update his facebook by ...   \n",
       "2       i dived many times for the ball managed to sa...   \n",
       "3        my whole body feels itchy and like its on fire    \n",
       "4       no it's not behaving at all i'm mad why am i ...   \n",
       "...                                                  ...   \n",
       "99995            now need followers to compleate follow    \n",
       "99996  i knew i had to explain something to my friend...   \n",
       "99997                        done tweeting til tomorrow    \n",
       "99998   act ii set is pretty breath taking love the r...   \n",
       "99999  if you don't have an artfire account to sell y...   \n",
       "\n",
       "                                                 spelled  \n",
       "0       www that's a summer you should got david carr...  \n",
       "1      is upset that he can't update his facebook by ...  \n",
       "2       i dived many times for the ball managed to sa...  \n",
       "3         my whole body feels itch and like its on fire   \n",
       "4       no it's not behaving at all i'm mad why am i ...  \n",
       "...                                                  ...  \n",
       "99995             now need followers to complete follow   \n",
       "99996  i knew i had to explain something to my friend...  \n",
       "99997                         done meeting til tomorrow   \n",
       "99998   act ii set is pretty breath taking love the r...  \n",
       "99999  if you don't have an attire account to sell yo...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Twitter Sentiment/spelt.csv', header=0, index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of apostrophe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         www thats a summer you should got david carr ...\n",
       "1        is upset that he cant update his facebook by t...\n",
       "2         i dived many times for the ball managed to sa...\n",
       "3           my whole body feels itch and like its on fire \n",
       "4         no its not behaving at all im mad why am i he...\n",
       "                               ...                        \n",
       "99995               now need followers to complete follow \n",
       "99996    i knew i had to explain something to my friend...\n",
       "99997                           done meeting til tomorrow \n",
       "99998     act ii set is pretty breath taking love the r...\n",
       "99999    if you dont have an attire account to sell you...\n",
       "Name: apostrophe, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\'', '', text)\n",
    "    return text\n",
    "\n",
    "data['apostrophe'] = data['spelled'].apply(clean_text)\n",
    "data.apostrophe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [www, thats, a, summer, you, should, got, davi...\n",
       "1        [is, upset, that, he, cant, update, his, faceb...\n",
       "2        [i, dived, many, times, for, the, ball, manage...\n",
       "3        [my, whole, body, feels, itch, and, like, its,...\n",
       "4        [no, its, not, behaving, at, all, im, mad, why...\n",
       "                               ...                        \n",
       "99995         [now, need, followers, to, complete, follow]\n",
       "99996    [i, knew, i, had, to, explain, something, to, ...\n",
       "99997                       [done, meeting, til, tomorrow]\n",
       "99998    [act, ii, set, is, pretty, breath, taking, lov...\n",
       "99999    [if, you, dont, have, an, attire, account, to,...\n",
       "Name: tokens, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens'] = data['apostrophe'].apply(word_tokenize)\n",
    "data.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [www, that, s, a, summer, you, should, got, da...\n",
       "1        [be, upset, that, he, ca, nt, update, his, fac...\n",
       "2        [I, dive, many, time, for, the, ball, manage, ...\n",
       "3        [my, whole, body, feel, itch, and, like, its, ...\n",
       "4        [no, its, not, behave, at, all, I, m, mad, why...\n",
       "                               ...                        \n",
       "99995          [now, need, follower, to, complete, follow]\n",
       "99996    [I, know, I, have, to, explain, something, to,...\n",
       "99997                         [do, meeting, til, tomorrow]\n",
       "99998    [act, ii, set, be, pretty, breath, take, love,...\n",
       "99999    [if, you, do, nt, have, an, attire, account, t...\n",
       "Name: lemmatized_token, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_words(word_list):\n",
    "    doc = nlp(\" \".join(word_list)) \n",
    "    lemmatized_text = [token.lemma_ for token in doc]\n",
    "    return lemmatized_text\n",
    "\n",
    "data['lemmatized_token'] = data['tokens'].apply(lemmatize_words)\n",
    "data.lemmatized_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords Removal then lower casing again as auto correct capitalised the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [www, summer, got, david, carr, third, day]\n",
       "1        [upset, ca, nt, update, facebook, texte, might...\n",
       "2        [i, dive, many, time, ball, manage, save, rest...\n",
       "3                    [whole, body, feel, itch, like, fire]\n",
       "4                      [behave, i, mad, i, i, ca, nt, see]\n",
       "                               ...                        \n",
       "99995                   [need, follower, complete, follow]\n",
       "99996    [i, know, i, explain, something, friend, say, ...\n",
       "99997                             [meeting, til, tomorrow]\n",
       "99998    [act, ii, set, pretty, breath, take, love, rea...\n",
       "99999    [nt, attire, account, sell, fun, thing, i, sug...\n",
       "Name: filtered_tokens, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "data['filtered_tokens'] = data['lemmatized_token'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "data['filtered_tokens'] = data['filtered_tokens'].apply(lambda tokens: [word.lower() for word in tokens])\n",
    "\n",
    "\n",
    "data['filtered_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the cleaned data to csv format to be applied in the respective models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleanedNspelt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
